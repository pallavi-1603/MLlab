{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FTUbAzZ3oiXZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/data.csv')"
      ],
      "metadata": {
        "id": "jrPO-bP_qUeB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['Unnamed: 32',\"id\"], axis=1, inplace=True)\n",
        "data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\n",
        "y = data.diagnosis.values\n",
        "x_data = data.drop(['diagnosis'], axis=1)"
      ],
      "metadata": {
        "id": "1ChsnVKArU7Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming x_data is a numpy array or pandas DataFrame\n",
        "x = (x_data - np.min(x_data)) / (np.max(x_data) - np.min(x_data))\n"
      ],
      "metadata": {
        "id": "H7CbTPSbv3rq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\n",
        "\n",
        "x_train = x_train.T\n",
        "x_test = x_test.T\n",
        "y_train = y_train.T\n",
        "y_test = y_test.T\n",
        "\n",
        "print(\"x train: \",x_train.shape)\n",
        "print(\"x test: \",x_test.shape)\n",
        "print(\"y train: \",y_train.shape)\n",
        "print(\"y test: \",y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhNpLCP9v8AP",
        "outputId": "37249cd6-759c-4d2d-f654-4eab0ed34642"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x train:  (30, 483)\n",
            "x test:  (30, 86)\n",
            "y train:  (483,)\n",
            "y test:  (86,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights_and_bias(dimension):\n",
        "    w = np.full((dimension,1),0.01)\n",
        "    b = 0.0\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "A-mAJHllwR3Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    y_head = 1/(1+np.exp(-z))\n",
        "    return y_head"
      ],
      "metadata": {
        "id": "uNjKyp0hwUsY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_backward_propagation(w,b,x_train,y_train):\n",
        "    # forward propagation\n",
        "    z = np.dot(w.T,x_train) + b\n",
        "    y_head = sigmoid(z)\n",
        "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
        "    cost = (np.sum(loss))/x_train.shape[1]      # x_train.shape[1]  is for scaling\n",
        "    # backward propagation\n",
        "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n",
        "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]                 # x_train.shape[1]  is for scaling\n",
        "    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n",
        "    return cost,gradients"
      ],
      "metadata": {
        "id": "X6PrzJQGwYsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
        "    cost_list = []\n",
        "    cost_list2 = []\n",
        "    index = []\n",
        "    # updating(learning) parameters is number_of_iterarion times\n",
        "    for i in range(number_of_iterarion):\n",
        "        # make forward and backward propagation and find cost and gradients\n",
        "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n",
        "        cost_list.append(cost)\n",
        "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
        "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
        "        if i % 10 == 0:\n",
        "            cost_list2.append(cost)\n",
        "            index.append(i)\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "    # we update(learn) parameters weights and bias\n",
        "    parameters = {\"weight\": w,\"bias\": b}\n",
        "    plt.plot(index,cost_list2)\n",
        "    plt.xticks(index,rotation='vertical')\n",
        "    plt.xlabel(\"Number of Iterarion\")\n",
        "    plt.ylabel(\"Cost\")\n",
        "    plt.show()\n",
        "    return parameters, gradients, cost_list"
      ],
      "metadata": {
        "id": "ob159E1Ywhkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(w,b,x_test):\n",
        "    # x_test is a input for forward propagation\n",
        "    z = sigmoid(np.dot(w.T,x_test)+b)\n",
        "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
        "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
        "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
        "    for i in range(z.shape[1]):\n",
        "        if z[0,i]<= 0.5:\n",
        "            Y_prediction[0,i] = 0\n",
        "        else:\n",
        "            Y_prediction[0,i] = 1\n",
        "\n",
        "    return Y_prediction"
      ],
      "metadata": {
        "id": "7pCdeiXfwr5H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mymodule"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr5eD4QZxPnz",
        "outputId": "8bdc9146-f373-487c-922b-69183e5491ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mymodule\n",
            "  Downloading myModule-1.0.0.tar.gz (787 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mymodule\n",
            "  Building wheel for mymodule (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mymodule: filename=myModule-1.0.0-py3-none-any.whl size=1413 sha256=2cdcfae4d015fdc631a533b7e726b48c29061c95d1a6a50b070d71cb04054f3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/64/ed/4ac2e7514f3e85b8aea309dff4c236817b10c4d0809e5511d8\n",
            "Successfully built mymodule\n",
            "Installing collected packages: mymodule\n",
            "Successfully installed mymodule-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def initialize_weights_and_bias(dim):\n",
        "    w = np.zeros((dim, 1))\n",
        "    b = 0\n",
        "    return w, b\n",
        "\n",
        "def compute_cost(w, b, x, y):\n",
        "    m = x.shape[1]\n",
        "    A = sigmoid(np.dot(w.T, x) + b)\n",
        "    cost = -1 / m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))\n",
        "    return cost\n",
        "\n",
        "def propagate(w, b, x, y):\n",
        "    m = x.shape[1]\n",
        "    A = sigmoid(np.dot(w.T, x) + b)\n",
        "    dw = 1 / m * np.dot(x, (A - y).T)\n",
        "    db = 1 / m * np.sum(A - y)\n",
        "    return dw, db\n",
        "\n",
        "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate, num_iterations):\n",
        "    # Initialize\n",
        "    dimension = x_train.shape[0]  # Number of features\n",
        "    w, b = initialize_weights_and_bias(dimension)\n",
        "    costs = []\n",
        "\n",
        "    # Gradient Descent\n",
        "    for i in range(num_iterations):\n",
        "        # Forward and Backward Propagation\n",
        "        dw, db = propagate(w, b, x_train, y_train)\n",
        "\n",
        "        # Update parameters\n",
        "        w -= learning_rate * dw\n",
        "        b -= learning_rate * db\n",
        "\n",
        "        # Record the costs\n",
        "        if i % 100 == 0:\n",
        "            cost = compute_cost(w, b, x_train, y_train)\n",
        "            costs.append(cost)\n",
        "            print(f\"Cost after iteration {i}: {cost}\")\n",
        "\n",
        "    # Evaluate model\n",
        "    y_prediction_train = predict(w, b, x_train)\n",
        "    y_prediction_test = predict(w, b, x_test)\n",
        "\n",
        "    train_accuracy = 100 - np.mean(np.abs(y_prediction_train - y_train)) * 100\n",
        "    test_accuracy = 100 - np.mean(np.abs(y_prediction_test - y_test)) * 100\n",
        "\n",
        "    print(\"Train accuracy: {} %\".format(train_accuracy))\n",
        "    print(\"Test accuracy: {} %\".format(test_accuracy))\n",
        "\n",
        "    return w, b\n",
        "\n",
        "# Assuming you have defined the predict function\n",
        "# def predict(w, b, x):\n",
        "#     ...\n",
        "\n",
        "# Assuming you have defined x_train, y_train, x_test, y_test, learning_rate, and num_iterations\n",
        "logistic_regression(x_train, y_train, x_test, y_test, learning_rate=1, num_iterations=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXDKVGxuwsS5",
        "outputId": "9a605da1-8abe-41b8-a793-86c1a0f44c86"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.6782740160052536\n",
            "Train accuracy: 80.74534161490683 %\n",
            "Test accuracy: 81.3953488372093 %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1.77806654e-02],\n",
              "        [ 1.10160388e-02],\n",
              "        [ 1.27806976e-01],\n",
              "        [ 1.95749649e+00],\n",
              "        [ 1.85931875e-05],\n",
              "        [ 2.68863405e-04],\n",
              "        [ 4.89020048e-04],\n",
              "        [ 2.63106803e-04],\n",
              "        [ 3.49357933e-05],\n",
              "        [-2.02145931e-05],\n",
              "        [ 1.25690784e-03],\n",
              "        [-3.98285024e-04],\n",
              "        [ 8.96937014e-03],\n",
              "        [ 2.02426962e-01],\n",
              "        [-3.60718647e-06],\n",
              "        [ 4.19150446e-05],\n",
              "        [ 6.03411729e-05],\n",
              "        [ 2.00740406e-05],\n",
              "        [-6.24803672e-06],\n",
              "        [ 6.24944780e-07],\n",
              "        [ 2.79506973e-02],\n",
              "        [ 1.99326360e-02],\n",
              "        [ 1.98774929e-01],\n",
              "        [ 3.39189908e+00],\n",
              "        [ 5.79135019e-05],\n",
              "        [ 8.53041205e-04],\n",
              "        [ 1.25862280e-03],\n",
              "        [ 4.60695564e-04],\n",
              "        [ 1.89671301e-04],\n",
              "        [ 3.52490835e-05]]),\n",
              " -1.5161875221606185)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QzleJ87Uw03M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}